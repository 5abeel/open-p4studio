/** @page BFRT_TM_OBJECTS_TF1 BF-RT Traffic Manager Objects (Tofino)

    @anchor BFRT_TM_OBJECTS_TF1_DIAG
    @image latex tf1_bf_rt_tm_objects.jpg "BF-RT TM Objects (Tofino)"
      <!-- Include an image file into the html doxygen, and do not show it yet -->
    @image html tf1_bf_rt_tm_objects.jpg "" width=0 height=0
      <!-- Now show the image file in html doxygen with a custom map -->
    @htmlonly
    <img src="tf1_bf_rt_tm_objects.jpg" border="0" alt="" usemap="#BFRT_TM_OBJECTS_TF1_MAP"/>
    <map name="BFRT_TM_OBJECTS_TF1_MAP" id="BFRT_TM_OBJECTS_TF1_MAP">
      <area shape="rect" id="node1" href="group__TF1__TM__QUEUE.html" title="TM Queue tables. " alt="" coords="960,350,1080,430"/>
      <area shape="rect" id="node2" href="group__TF1__TM__PORT__GROUP__CFG.html#TF1_TM_PORT_GROUP_CFG__PG_QUEUES" title="tm.port.group_cfg.pg_queues" alt="" coords="250,200,410,230"/>
      <area shape="rect" id="node3" href="group__TF1__TM__PORT__GROUP.html#TF1_TM_PORT_GROUP__EGRESS_QID_QUEUES_0" title="tm.port.group.egress_qid_queues_*" alt="" coords="410,230,530,260"/>
      <area shape="rect" id="node4" href="group__TF1__TM__PORT__GROUP.html#TF1_TM_PORT_GROUP__INGRESS_QID_MAP_0" title="tm.port.group.ingress_qid_map_*" alt="" coords="240,360,420,380"/>
      <area shape="rect" id="node5" href="BFRT_TM_PORT_TO_QUEUE_REL.html#BFRT_TM_PORT_TO_QUEUE_REL_DIAG" title="QID" alt="" coords="290,270,410,320"/>
      <area shape="rect" id="node6" href="BFRT_TM_PORT_TO_QUEUE_REL.html#BFRT_TM_PORT_TO_QUEUE_REL_DIAG" title="pg_queue" alt="" coords="550,200,670,260"/>
      <area shape="rect" id="node7" href="BFRT_TM_PORT_TO_QUEUE_REL.html#BFRT_TM_PORT_TO_QUEUE_REL_DIAG" title="queue_nr" alt="" coords="490,350,610,420"/>
      <area shape="rect" id="node8" href="group__TF1__TM__PORT__GROUP__CFG.html#TF1_TM_PORT_GROUP_CFG__INGRESS_QID_MAX" title="tm.port.group_cfg.ingress_qid_max" alt="" coords="450,450,550,480"/>
      <area shape="rect" id="node9" href="group__TF1__TM__PORT__GROUP__CFG.html#TF1_TM_PORT_GROUP_CFG__PG_QUEUES" title="tm.port.group_cfg.pg_queues" alt="" coords="580,450,680,480"/>
      <area shape="rect" id="node10" href="group__TF1__TM__PORT__GROUP.html" title="tm.port.group" alt="" coords="140,570,250,620"/>
      <area shape="rect" id="node11" href="group__TF1__TM__COUNTER.html" title="Counters at TM objects. " alt="" coords="1130,180,1300,320"/>
      <ARea shape="rect" id="node12" href="group__TF1__TM__PORT.html" title="TM Port tables. " alt="" coords="520,570,640,630"/>
      <area shape="rect" id="node13" href="group__TF1__TM__POOL.html" title="TM Pool object. " alt="" coords="960,470,1350,1000"/>
      <area shape="rect" id="node14" href="group__TF1__TM__SCHEDULER.html" title="TM Scheduler tables. " alt="" coords="700,250,880,530"/>
      <area shape="rect" id="node15" href="group__TF1__TM__PIPE.html" title="TM Pipe tables. " alt="" coords="160,700,280,770"/>
      <area shape="rect" id="node16" href="group__TF1__TM__PIPE__MULTICAST__FIFO.html" title="TM Multicast FIFO" alt="" coords="380,690,520,720"/>
      <area shape="rect" id="node17" href="group__TF1__TM__MIRROR.html" title="TM Mirror tables. " alt="" coords="380,730,520,770"/>
      <area shape="rect" id="node18" href="group__TF1__TM__PORT__DPG.html" title="TM Port DPG" alt="" coords="610,730,720,770"/>
      <area shape="rect" id="node19" href="group__TF1__TM__PPG.html" title="PFC" alt="" coords="450,870,720,980"/>
      <area shape="rect" id="node20" href="group__TF1__TM__PPG.html" title="iCoS" alt="" coords="770,650,930,790"/>
      <area shape="rect" id="node21" href="group__TF1__TM__PPG__CFG.html" title="TM Port Priority Group" alt="" coords="720,800,890,890"/>
      <area shape="rect" id="node22" href="group__TF1__TM__CFG.html" title="TM Device" alt="" coords="0,700,120,770"/>
    </map>
    @endhtmlonly
 */

/** @addtogroup TF1_TM

  @note <b>Data Field Id meaning</b>
  <br>The Data Field 'id' value in the BFRT TM tables (also in the bf_rt_tm_*.json files) conveys a hint to what is the order of execution
  for the underlying TM APIs when several data fields are given to update an entry (on Add, Mod, Delete operations), or to change all entries
  in a table (on Clear). This order becomes important to consider when a table has a meaningful execution sequence to update its entry
  e.g. to set some feature properties first and 'enable/disable' that feature, or how to respond if one of data fields got an error
  on low-level TM functions and the entry has been changed partially.
  <br>If there is a need to execute the underlying TM APIs in some custom order, or to ensure more granular error handling,
  then the caller should split a table entry change into several BF-RT TM API requests with specific data fields in each request.

    @{
      @defgroup TF1_TM_SCHEDULER tf1.tm.scheduler object

      @brief TM Scheduler tables

      BFRT TM Scheduler tables are child tables of related TM objects:
      <table>
      <tr>
        <td> @ref TF1_TM_PIPE "TM Pipe"</td>
        <td> @ref TF1_TM_PIPE_SCHED_CFG "tm.pipe.sched_cfg" </td>
      </tr>
      <tr>
        <td rowspan=2>@ref TF1_TM_PORT "TM Port"</td>
        <td> @ref TF1_TM_PORT_SCHED_CFG "tm.port.sched_cfg"</td>
      </tr>
      <tr>
        <td>@ref TF1_TM_PORT_SCHED_SHAPING "tm.port.sched_shaping"</td>
      </tr>
      <tr>
        <td rowspan=2>@ref TF1_TM_QUEUE "TM Queue"</td>
        <td> @ref TF1_TM_QUEUE_SCHED_CFG "tm.queue.sched_cfg" </td>
      </tr>
      <tr>
        <td> @ref TF1_TM_QUEUE_SCHED_SHAPING "tm.queue.sched_shaping"</td>
      </tr>
      </table>
    @}
*/

/** @addtogroup TF1_TM_COUNTER

    @brief Counters at TM objects
 */

/** @addtogroup TF1_TM_POOL

    @brief TM Pool object
 */

/** @addtogroup TF1_TM_PIPE

    @brief TM Pipe tables

    All the BFRT Pipe tables are keyless with default entry.
    Each available Pipe is addressed by <i>dev_tgt.pipe_id</i> pipe identifier (0..3) or PIPE_ALL for all pipes.

 */

/** @addtogroup TF1_TM_PIPE_CFG

    ### See also ###

  <table>
    <tr>
      <th>Data field</th>
      <th>TM API</th>
      <th>Other data fields</th>
    </tr>
    <tr>
      <td colspan=3><b>Dropped packet redirection (Negative Mirroring)</b></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_PIPE_CFG__MIRROR_DROP_DEV_PORT  "mirror_drop_dev_port"</td>
      <td rowspan=4> @ref bf_tm_port_mirror_on_drop_dest_set(), bf_tm_port_mirror_on_drop_dest_get()</td>
      <td>The Port assignment is also reflected by @ref TF1_TM_PORT_CFG__MIRROR_DROP_DESTINATION "tm.port.cfg.mirror_drop_destination" R/O flag.</td>
    </tr>
    <tr>
      <td> @ref TF1_TM_PIPE_CFG__MIRROR_DROP_QUEUE_NR  "mirror_drop_queue_nr"</td>
      <td>The <i>mirror_drop_dev_port</i> must have that queue mapped to a physical queue.
        This queue number will change when the physical queue becomes re-mapped to another port in its group.
        <br>The Queue assignment is also reflected by @ref TF1_TM_QUEUE_CFG__MIRROR_DROP_DESTINATION "tm.queue.cfg.mirror_drop_destination" R/O flag.
      </td>
    </tr>
    <tr>
      <td> @ref TF1_TM_PIPE_CFG__MIRROR_DROP_PG_ID  "mirror_drop_pg_id"</td>
      <td rowspan=2><i>mirror_drop_pg_id and mirror_drop_pg_queue</i> tuple identifies a physical queue which is mapped to a port queue identified by <i>mirror_drop_dev_port, mirror_drop_queue_nr</i> tuple. Make sure to set the destination physical queue in accordance to the device port queue mapping when it is changed.</td>
    </tr>
    <tr>
      <td> @ref TF1_TM_PIPE_CFG__MIRROR_DROP_PG_QUEUE  "mirror_drop_pg_queue"</td>
    </tr>
    <tr>
      <td colspan=3><b>Egress limits</b></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_PIPE_CFG__EG_LIMIT_CELLS "eg_limit_cells"</td>
      <td> @ref bf_tm_pipe_egress_limit_set(), bf_tm_pipe_egress_limit_get()</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_PIPE_CFG__EG_HYSTERESIS_CELLS "eg_hysteresis_cells"</td>
      <td> @ref bf_tm_pipe_egress_hysteresis_set(),bf_tm_pipe_egress_hysteresis_get()</td>
      <td></td>
    </tr>
  </table>
*/

/** @addtogroup TF1_TM_PIPE_SCHED_CFG

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PIPE_SCHED_CFG__PACKET_IFG_COMPENSATION "packet_ifg_compensation" | @ref bf_tm_sched_pkt_ifg_compensation_set(), bf_tm_sched_pkt_ifg_compensation_get() | |

 */

/** @addtogroup TF1_TM_PORT
    @brief TM Port tables
 */

/** @addtogroup TF1_TM_PORT_GROUP_CFG

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_GROUP_CFG__INGRESS_QID_MAX "ingress_qid_max" |  | The same R/O value is at @ref TF1_TM_QUEUE_MAP__INGRESS_QID_MAX "tm.queue.map.ingress_qid_max" |
 */

/** @addtogroup TF1_TM_PORT_GROUP

    @note @ref BFRT_TM_PORT_TO_QUEUE_REL_DIAG "Queue to Port mapping diagram."

    This table ensures the port group queue resources are consistently assigned for all ports in the group.

    @sa bf_tm_port_q_mapping_get(), bf_tm_port_q_mapping_set()

  <table>
  <tr>
    <th>Action / Data field</th>
    <th>Notes and Examples</th>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__PG_DEV_PORTS "pg_dev_ports"</td>
    <td>Example (TF1): [4,5,6,7] for pg_id=1 on pipe=0;  [260,261,262,263] for pg_id=1 on pipe=2.</td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__SEQ "'seq' action"</td>
    <td>Fill each ingress_qid_map_[n] list with sequences 0..port_queue_count[n] the same way as default mapping does. </td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__SEQ__PORT_QUEUE_COUNT "'seq' port_queue_count"</td>
    <td>Same as for the 'map' action.</td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__EVEN "'even' action"</td>
    <td>Fill each ingress_qid_map[n] list with equally sized chunks using port_queue_count[n],
      <br>e.g. for 8 queues: (0,0,0,0, 1,1,1,1, 2,2,2,2, 3,3,3,3, 4,4,4,4, 5,5,5,5, 6,6,6,6, 7,7,7,7).
      <br>When size of a chunk is 1 or less, like when port_queue_count[n] > 16 on TF1, then the rest of the queues is assigned to 0,
      <br>e.g. for 17 queues: (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 0,0,0..0)
    </td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__EVEN__PORT_QUEUE_COUNT "'even' port_queue_count"</td>
    <td>Same as for the 'map' action.</td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__CROP "'crop' action"</td>
    <td>Apply new port_queue_count[] to the current ingress_qid_map[]
        replacing with 0 all values greater or equal to the port_queue_count[]-1 or 0, e.g.
        <br>a) the default map will not change for 10 queues eventually leaving two physical queues not used;
        <br>b) default map becomes (0,1,2,3,4,0,0,0, 0,1,2,3,4,0,0,0, 0,1,2,3,4,0,0,0, 0,1,2,3,4,0,0,0) for 5 queues.
        <br><br><i>port_queue_count</i> is mandatory field for this action as it provides the crop factor to apply.
    </td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__CROP__PORT_QUEUE_COUNT "'crop' port_queue_count"</td>
    <td>Same as for the 'map' action.</td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__MAP "'map' action"</td>
    <td>Custom queue mapping.</td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__MAP__PORT_QUEUE_COUNT "'crop' port_queue_count"</td>
    <td>
      How many <b>physical queues</b> are carved to each egress port in this port group from its fixed resource equal to
      @ref TF1_TM_PORT_GROUP_CFG__PG_QUEUES "tm.port.group_cfg.pg_queues".
      <br>Each item becomes a range for <b>port queue number</b> values used in the ingress_qid_map_* with constraints applied to an item:
      <ul>
        <li>this data field list must contain items for all ports in the port group, i.e. pg_dev_ports[].size().</li>
        <li>if this data field is omitted then current carving is used for the program group and all the ingress_qid_map_* fields provided
           must have appropriate number of queues.</li>
        <li>it is greater or equal to how many unique items are in the ingress_qid_map_* of the appropriate port.</li>
        <li>the sum for all the items must be less or equal to the @ref TF1_TM_PORT_GROUP_CFG__PG_QUEUES "tm.port.group_cfg.pg_queues".</li>
      </ul>
      <br><b>Example 1</b>: TF1, the default TM setup: (8, 8, 8, 8)
      <br><b>Example 2</b>: TF1, some custom queue assignment: (2, 4, 16, 10) – 2 queues on the first port of the port group, 4 on the second, etc
    </td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__MAP__INGRESS_QID_MAP_0 "ingress_qid_map_*"</td>
    <td>If port_queue_count[n] == 0 then ingress_qid_queues_[n] is empty list.
      <br>At least one of ingress_qid_map data fields need to be present in the data for this action, or the port_queue_count changed.
      <br>
      <br><b>Example 1</b>: TF1, the default TM setup
      <br>0: (0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7)
      <br>1: (0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7)
      <br>2: (0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7)
      <br>3: (0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7)
      <br>
      <br><b>Example 2</b>: TF1, the custom queue setup:
      <br>0: (0,1,0,1,0,1,0,1, 0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1, 0,0,0,0,1,1,1,1),
      <br>1: (0,1,2,3,0,1,2,3, 0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1, 2,2,2,2,3,3,3,3),
      <br>2: (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15, 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15),
      <br>3: (0,1,2,3,4,5,6,7,8,9, 0,1, 2,2,2,2,2,2,2,2,2,2, 9,9,9,9,9,9,9,9,9,9)
    </td>
  </tr>
  <tr>
    <td>@ref TF1_TM_PORT_GROUP__MAP__EGRESS_QID_QUEUES_0 "egress_qid_queues_*"</td>
    <td>If port_queue_count[n] == 0 then egress_qid_queues_[n] is empty list.
      <br>At least one of ingress_qid_map data fields need to be present in the data for this action, or the port_queue_count changed.
      <br>
      <br><b>Example 1</b>: TF1, the default TM setup:
      <br>0: (0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7, 0,1,2,3,4,5,6,7)
      <br>1: (8,9,10,11,12,13,14,15, 8,9,10,11,12,13,14,15, 8,9,10,11,12,13,14,15, 8,9,10,11,12,13,14,15,)
      <br>2: (16,17,18,19,20,21,22,23, 16,17,18,19,20,21,22,23, 16,17,18,19,20,21,22,23, 16,17,18,19,20,21,22,23)
      <br>3: (24,25,26,27,28,29,30,31, 24,25,26,27,28,29,30,31, 24,25,26,27,28,29,30,31, 24,25,26,27,28,29,30,31)
      <br><b>Example 2</b>: TF1 the custom queue setup:
      <br>0: (0,1,0,1,0,1,0,1, 0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1, 0,0,0,0,1,1,1,1),
      <br>1: (2,3,4,5,2,3,4,5, 2,2,2,2,2,2,2,2, 3,3,3,3,3,3,3,3, 4,4,4,4,5,5,5,5),
      <br>2: (6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21),
      <br>3: (22,23,24,25,26,27,28,29,30,31, 22,23, 24,24,24,24,24,24,24,24,24,24, 31,31,31,31,31,31,31,31,31,31)
    </td>
  </tr>
  </table>
 */

/** @addtogroup TF1_TM_PORT_CFG

    @note @ref BFRT_TM_PORT_TO_QUEUE_REL_DIAG "Queue to Port mapping diagram."

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_CFG__PORT_QUEUES_COUNT "port_queues_count" |  | Modified via @ref TF1_TM_PORT_GROUP "tm.port.group". The same value is @ref TF1_TM_PORT_GROUP__MAP__PORT_QUEUE_COUNT "tm.port.group.port_queue_count[pg_port_nr]" |
| @ref TF1_TM_PORT_CFG__INGRESS_QID_MAP "ingress_qid_map" | @ref bf_tm_port_q_mapping_get() | Modified via @ref TF1_TM_PORT_GROUP "tm.port.group". The same array as @ref TF1_TM_PORT_GROUP__MAP__INGRESS_QID_MAP_0 "tm.port.group.ingress_qid_map_{pg_port_id}" for the pg_id entry. |
| @ref TF1_TM_PORT_CFG__EGRESS_QID_QUEUES "egress_qid_queues" |  | Modified via @ref TF1_TM_PORT_GROUP "tm.port.group".  The same array field as  @ref TF1_TM_PORT_GROUP__MAP__EGRESS_QID_QUEUES_0 "tm.port.group.egress_qid_queues_{pg_port_id}" for the pg_id entry. |
| @ref TF1_TM_PORT_CFG__COPY_TO_CPU "copy_to_cpu" | bf_mc_get_copy_to_cpu() |  |
| @ref TF1_TM_PORT_CFG__MIRROR_DROP_DESTINATION "mirror_drop_destination" |  @ref bf_tm_port_mirror_on_drop_dest_get() | <i>Queue[pg_id, mirror_drop_pg_queue]</i> has the same value in its @ref TF1_TM_QUEUE_CFG__MIRROR_DROP_DESTINATION "tm.queue.cfg.mirror_drop_destination". |
| @ref TF1_TM_PORT_CFG__PKT_EXTRACTION_CREDITS "pkt_extraction_credits" | @ref bf_tm_port_credits_get() |  |

*/

/** @addtogroup TF1_TM_PORT_BUFFER

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_BUFFER__CT_ENABLE "ct_enable" | @ref bf_tm_port_cut_through_enable_status_get(),  @ref bf_tm_port_cut_through_enable(), @ref bf_tm_port_cut_through_disable() | @ref TF1_PORT_PORT__CUT_THROUGH_EN "port.$CUT_THROUGH_EN" |
| @ref TF1_TM_PORT_BUFFER__UC_CT_LIMIT_CELLS "uc_ct_limit_cells" | @ref bf_tm_port_uc_cut_through_limit_get(), @ref bf_tm_port_uc_cut_through_limit_set() |  |
| @ref TF1_TM_PORT_BUFFER__IG_LIMIT_CELLS "ig_limit_cells" | @ref bf_tm_port_ingress_drop_limit_set(), @ref bf_tm_port_ingress_drop_limit_get() |  |
| @ref TF1_TM_PORT_BUFFER__IG_HYSTERESIS_CELLS "ig_hysteresis_cells" | @ref bf_tm_port_ingress_hysteresis_set(), @ref bf_tm_port_ingress_hysteresis_get() |  |
| @ref TF1_TM_PORT_BUFFER__EG_LIMIT_CELLS "eg_limit_cells" | @ref bf_tm_port_egress_drop_limit_set(), @ref bf_tm_port_egress_drop_limit_get() |  |
| @ref TF1_TM_PORT_BUFFER__EG_HYSTERESIS_CELLS "eg_hysteresis_cells" | @ref bf_tm_port_egress_hysteresis_set(), @ref bf_tm_port_egress_hysteresis_get() |  |
| @ref TF1_TM_PORT_BUFFER__SKID_LIMIT_CELLS "skid_limit_cells" | @ref bf_tm_port_skid_limit_set(), @ref bf_tm_port_skid_limit_get() |  |

*/

/** @addtogroup TF1_TM_PORT_FLOWCONTROL

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_FLOWCONTROL__MODE_TX "mode_tx" | @ref bf_tm_port_flowcontrol_mode_set(), @ref bf_tm_port_flowcontrol_mode_get() |  |
| @ref TF1_TM_PORT_FLOWCONTROL__MODE_RX "mode_rx" | @ref bf_tm_port_flowcontrol_rx_set(), @ref bf_tm_port_flowcontrol_rx_get() |  |
| @ref TF1_TM_PORT_FLOWCONTROL__COS_TO_ICOS "cos_to_icos" | @ref bf_tm_port_pfc_cos_mapping_set(), @ref bf_tm_port_pfc_cos_mapping_get() |  |

*/

/** @addtogroup TF1_TM_PORT_SCHED_CFG

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_SCHED_CFG__SCHEDULING_SPEED "scheduling_speed"  | @ref bf_tm_sched_port_enable(), @ref bf_tm_sched_port_disable() |  |
| @ref TF1_TM_PORT_SCHED_CFG__MAX_RATE_ENABLE "max_rate_enable" | @ref bf_tm_sched_port_shaping_enable(), @ref bf_tm_sched_port_shaping_disable() |  |

*/

/** @addtogroup TF1_TM_PORT_SCHED_SHAPING

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_SCHED_SHAPING__PROVISIONING "provisioning" | @ref bf_tm_sched_port_shaping_rate_get_provisioning(), @ref bf_tm_sched_port_shaping_rate_get(), @ref bf_tm_sched_port_shaping_rate_set() |  |
| @ref TF1_TM_PORT_SCHED_SHAPING__UNIT "unit" |^|  |
| @ref TF1_TM_PORT_SCHED_SHAPING__MAX_RATE "max_rate" |^|  |
| @ref TF1_TM_PORT_SCHED_SHAPING__MAX_BURST_SIZE "max_burst_size" |^|  |

*/

/** @addtogroup TF1_TM_PPG

    @brief TM Port Priority Group tables

    On ingress @ref TF1_TM_PORT "Port", to provide desired QoS characteristics (lossless/lossy, real-time, etc.),
    each packet can be mapped to a 'Port Priority Group' object by iCoS value.

    <i>Port Priority Group</i> is either the ingress @ref TF1_TM_PORT_DPG "Port Default Priority Group (DPG)",
    or a @ref TF1_TM_MIRROR_DPG "Mirror Port DPG",
    or it is a dedicated @ref TF1_TM_PPG_CFG "PFC Priority Group (PPG)" allocated on the ingress Port to be applied for some iCoS subset.

    There is one DPG per-Port, whereas PPGs are allocated from the common resource pool of 128 PPGs per each Pipe.

    A PPG might be PFC-enabled making its subset of assigned iCoS ‘lossless’ on the Port.

    Each Pipe has one DPG for its ingress Mirroring Port to map iCoS to PPGs, but PFC treatment is not allowed on them.

    @sa TF1_TM_PORT_DPG, TF1_TM_MIRROR_DPG, TF1_TM_PPG_CFG

    <hr>

    @section BFRT_TF1_TM_PPG_WORKFLOW Tofino-1 TM Priority Group workflow
    <table>
    <tr>
      <th></th>
      <th>TM API</th>
      <th>BFRT TM PPG</th></tr>
    <tr>
      <td>Get Id of Port's DPG</td>
      <td>Get a low-level TM handle for Port's DPG (dpg_h)
        <br>@ref bf_tm_ppg_defaultppg_get (dev, port, &dpg_h)
      </td>
      <td>Use dev_port as a key to @ref TF2_TM_PORT_DPG "tm.port.dpg"
      </td>
    </tr>
    <tr><td colspan=3></tr>
    <tr>
      <td>Get/Set the Port's DPG buffer settings</td>
      <td>Multiple calls to <br>bf_tm_ppg_*_get(dev, dpg_h, &value)<br> bf_tm_ppg_*_set(dev, dpg_h, &value)</td>
      <td>Several properties at once: <br>@ref TF1_TM_PORT_DPG "tm.port.dpg.get(dev_port, field_name(s))"<br> @ref TF1_TM_PORT_DPG "tm.port.dpg.mod(dev_port, field_name(s)=value(s))"</td>
    </tr>
    <tr>
      <td>Get Port's DPG iCoS mapping</td>
      <td>@ref bf_tm_ppg_icos_mapping_get (dev, dpg_h, &old_dpg_icos)</td>
      <td>@ref TF1_TM_PORT_DPG "tm.port.dpg.get(dev_port, icos_*)"</td>
    </tr>
    <tr>
      <td>Set Port's DPG iCoS mapping</td>
      <td colspan=2 align=center>TM driver does it indirectly with PPG setting</td>
    </tr>
    <tr><td colspan=3></tr>
    <tr>
      <td>Get Id of a PPG</td>
      <td>Low-level TM handle for a PPG (ppg_h)</td>
      <td>User-defined ppg_id.
          <br>Low level handle is kept by BFRT internally
      </td>
    </tr>
    <tr>
      <td>Allocate new PPG; it is bound to the Port.</td>
      <td>Allocate with default settings and obtain a handle (ppg_h)<br> @ref bf_tm_ppg_allocate (dev, port, &ppg_h)</td>
      <td>Allocate with custom Id, iCoS and buffer settings.  <br>@ref TF2_TM_PPG_CFG__DEV_PORT "tm.ppg.cfg.add_with_device_port(pipe, ppg_id, dev_port, icos_N)" <br>@ref TF2_TM_PPG_CFG__MIRROR_PORT "tm.ppg.cfg.add_with_mirror_port(pipe, ppg_id, icos_N))"</td>
    </tr>
    <tr>
      <td></td>
      <td>The client application is responsible to keep the PPG handle and free the PPG when it is not needed.</td>
      <td>@ref TF2_TM_PORT_DPG__ICOS_PPG_MAP "tm.port.dpg.icos_ppg_map[]"
        <br>keeps track of ppg_id-s allocated for each iCoS.</td>
    </tr>
    <tr>
      <td>Get and Set the new PPG's parameters</td>
      <td>bf_tm_ppg_*_get(dev, ppg_h, &value), ....  <br>bf_tm_ppg_*_set(dev, ppg_h, &value), ....</td>
      <td>@ref TF1_TM_PPG_CFG "tm.ppg.cfg.mod_with_*(pipe, ppg_id, field_name(s)=value(s))"</td>
    </tr>
    <tr>
      <td>Assign/Release iCoS on the PPG.</td>
      <td>@ref bf_tm_ppg_icos_mapping_set (dev, ppg_h, new_ppg_icos)</td>
      <td>@ref TF1_TM_PPG_CFG "tm.ppg.cfg.mod_with_*(pipe, ppg_id, icos_N=True)"</td>
    </tr>
    <tr>
      <td></td>
      <td colspan=2 align=center>TM driver updates the Port's DPG iCoS when PPG does iCoS changes.  <br>Application should track PPGs left without iCoS assignments on the Port to free it explicitly.</td>
    </tr>
    <tr>
      <td>PFC setup on the PPG</td>
      <td>@ref bf_tm_ppg_lossless_treatment_enable (dev, ppg_h) <br> @ref bf_tm_ppg_skid_limit_set (dev, ppg_h, limit) <br> @ref bf_tm_ppg_lossless_treatment_disable (dev, ppg_h)</td>
      <td>@ref TF1_TM_PPG_CFG "tm.ppg.cfg.mod_with_dev_port(pipe, ppg_id, pfc_enable=True, pfc_field_name(s)=value(s))" </td>
    </tr>
    <tr><td colspan=3></tr>
    <tr>
      <td>Mirroring Port</td>
      <td>With dev_port=72 the same way as for an 'external port' (0–71), except a PPG allocated can't be PFC-enabled</td>
      <td>DPG: set up QoS settings with @ref TF1_TM_MIRROR_DPG "tm.mirror.dpg" the same way
        @ref TF1_TM_PORT_DPG "tm.port.dpg" table using pipe_id as a key.  
        <br>PPG: same @ref TF1_TM_PPG_CFG "tm.ppg.cfg" table with @ref TF1_TM_PPG_CFG__MIRROR_PORT "mirror_port" action.
      </td>
    </tr>
    <tr><td colspan=3></tr>
    <tr>
      <td>Release PPG</td>
      <td>@ref bf_tm_ppg_free (dev, ppg_h)  for each of PPG allocated</td>
      <td> 1) @ref TF1_TM_PPG_CFG "tm.ppg.cfg.delete(pipe, ppg_id)" one selected PPG
         <br>or<br>
           2) @ref TF1_TM_PPG_CFG "tm.ppg.cfg.clear(pipe)"  for all Ports on the pipe or for PIPE_ALL
      </td>
    </tr>
    <tr>
      <td></td>
      <td colspan=2 align=center>Application is responsible to free all the unused PPGs.<br> TM driver releases iCoS back to the Port's DPG if any is left at the PPG on free.<br> TM driver may keep old buffer settings at the released PPG objects.
      </td>
    </tr>
  </table>
 */

/** @addtogroup TF1_TM_PPG_CFG

    @note @ref BFRT_TF1_TM_PPG_WORKFLOW "PPG workflow."

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PPG_CFG__DEV_PORT "'dev_port' action"| | The PPG is allocated for a regular Port on the Pipe (dev_tgt.pipe_id). |
| @ref TF1_TM_PPG_CFG__DEV_PORT__DEV_PORT "dev_port"| | TM allows to allocate not more than 8 PPGs per Port, either assigned to iCoS or not. |
| @ref TF1_TM_PPG_CFG__DEV_PORT__PFC_ENABLE "pfc_enable"| @ref bf_tm_ppg_lossless_treatment_get(), @ref bf_tm_ppg_lossless_treatment_disable(), @ref bf_tm_ppg_lossless_treatment_enable() | The Default property of PPG is to treat traffic as ‘lossy’. ‘Lossless’ traffic should not be dropped in TM except in worst-case scenarios when the upstream device is not honoring port pause or priority flow control (PFC), or when the Skid buffer space is full. |
| @ref TF1_TM_PPG_CFG__DEV_PORT__PFC_SKID_MAX_CELLS "pfc_skid_max_cells"| @ref bf_tm_ppg_skid_limit_get(), @ref bf_tm_ppg_skid_limit_set() | This buffer space is used when the PPGs configured ingress buffer limit has been used up. When traffic flow is directed to the skid buffer space, a PFC or Pause message is sent immediately to the upstream device. Cannot be set more than the Skid pool total size. Once this limit is reached, then even the lossless traffic will be dropped. Before consuming the Skid pool, the PFC would be asserted for lossless flows. |
| @ref TF1_TM_PPG_CFG__MIRROR_PORT "'mirror_port' action" | | The PPG is allocated for a Mirror port on the Pipe (dev_tgt.pipe_id). |
| @ref TF1_TM_PPG_CFG__ICOS_0 "icos_*" | @ref bf_tm_ppg_icos_mapping_set(),  @ref bf_tm_ppg_icos_mapping_get() |  All iCoS are initially assigned to the port's default PG (DPG). PPG allows explicit iCoS assignment to/from its 'parent' Port's DPG. To reassign some iCoS to another PPG it should be released back to the DPG first. |
| @ref TF1_TM_PPG_CFG__GUARANTEED_CELLS "guaranteed_cells" | @ref bf_tm_ppg_guaranteed_min_limit_get(), bf_tm_ppg_guaranteed_min_limit_set() | |
| @ref TF1_TM_PPG_CFG__HYSTERESIS_CELLS "hysteresis_cells" | @ref bf_tm_ppg_guaranteed_min_skid_hysteresis_get(), bf_tm_ppg_guaranteed_min_skid_hysteresis_set() |  The same hysteresis limit is applied to the guaranteed minimum buffer and to the Skid Pool if the PPG is lossless and its pfc_skid_max_cells is non-zero |
| @ref TF1_TM_PPG_CFG__POOL_ID "pool_id" | @ref bf_tm_ppg_app_pool_usage_disable(), @ref bf_tm_ppg_app_pool_usage_get(), @ref bf_tm_ppg_app_pool_usage_set() | |
| @ref TF1_TM_PPG_CFG__POOL_MAX_CELLS "pool_max_cells" |^| |
| @ref TF1_TM_PPG_CFG__DYNAMIC_BAF "dynamic_baf" |^| |

*/

/** @addtogroup TF1_TM_PORT_DPG

    @note @ref BFRT_TF1_TM_PPG_WORKFLOW "PPG workflow."

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_PORT_DPG__ICOS_0 "icos_*" | @ref bf_tm_ppg_icos_mapping_set(),  bf_tm_ppg_icos_mapping_get() | All iCoS are initially assigned to the DPG and all the icos_* bits are True. If an iCoS bit is set to False, then it means a PPG object is assigned the iCoS and the PPG’s parameters are applied instead. Use @ref TF1_TM_PORT_DPG__ICOS_PPG_MAP "tm.port.dpg.icos_ppg_map[icos]" for ppg_id of that PPG object to access its properties. |
| @ref TF1_TM_PORT_DPG__GUARANTEED_CELLS "guaranteed_cells" | @ref bf_tm_ppg_guaranteed_min_limit_get(), bf_tm_ppg_guaranteed_min_limit_set() | |
| @ref TF1_TM_PORT_DPG__HYSTERESIS_CELLS "hysteresis_cells" | @ref bf_tm_ppg_guaranteed_min_skid_hysteresis_get(), bf_tm_ppg_guaranteed_min_skid_hysteresis_set() | Hysteresis limit is the number of cells the PPG usage should fall by from its limit value. Once usage limit is below hysteresis, then the appropriate condition is cleared. The same hysteresis limit is applied to the guaranteed minimum buffer and to the Skid Pool if the PPG is lossless and its pfc_skid_max_cells is non-zero. |
| @ref TF1_TM_PORT_DPG__POOL_ID "pool_id" | @ref bf_tm_ppg_app_pool_usage_disable(), @ref bf_tm_ppg_app_pool_usage_get(), @ref bf_tm_ppg_app_pool_usage_set() | |
| @ref TF1_TM_PORT_DPG__POOL_MAX_CELLS "pool_max_cells" |^| |
| @ref TF1_TM_PORT_DPG__DYNAMIC_BAF "dynamic_baf" |^| |

*/

/** @addtogroup TF1_TM_MIRROR

    @brief TM Mirror tables
*/

/** @addtogroup TF1_TM_MIRROR_DPG

    @note @ref BFRT_TF1_TM_PPG_WORKFLOW "PPG workflow."

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_MIRROR_DPG__ICOS_0 "icos_*" | @ref bf_tm_ppg_icos_mapping_set(), @ref bf_tm_ppg_icos_mapping_get() | All iCoS are initially assigned to the DPG and all the icos_* bits are True. If an iCoS bit is set to False, then it means a PPG object is assigned the iCoS and the PPG’s parameters are applied instead. Use @ref TF1_TM_MIRROR_DPG__ICOS_PPG_MAP "tm.mirror.dpg.icos_ppg_map[icos]" for ppg_id of that PPG object to access its properties. |
| @ref TF1_TM_MIRROR_DPG__GUARANTEED_CELLS "guaranteed_cells" | @ref bf_tm_ppg_guaranteed_min_limit_get(), @ref bf_tm_ppg_guaranteed_min_limit_set() | |
| @ref TF1_TM_MIRROR_DPG__HYSTERESIS_CELLS "hysteresis_cells" | @ref bf_tm_ppg_guaranteed_min_skid_hysteresis_get(), @ref bf_tm_ppg_guaranteed_min_skid_hysteresis_set() | |
| @ref TF1_TM_MIRROR_DPG__POOL_ID "pool_id" | @ref bf_tm_ppg_app_pool_usage_disable(), @ref bf_tm_ppg_app_pool_usage_get(), @ref bf_tm_ppg_app_pool_usage_set() | |
| @ref TF1_TM_MIRROR_DPG__POOL_MAX_CELLS "pool_max_cells" |^| |
| @ref TF1_TM_MIRROR_DPG__DYNAMIC_BAF "dynamic_baf" |^| |

*/

/** @addtogroup TF1_TM_QUEUE

    @brief TM Queue tables

    @note @ref BFRT_TM_PORT_TO_QUEUE_REL_DIAG "Queue to Port mapping diagram."
 */

/** @addtogroup TF1_TM_QUEUE_CFG

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_QUEUE_CFG__MIRROR_DROP_DESTINATION "mirror_drop_destination" | @ref bf_tm_port_mirror_on_drop_dest_get() |  |
| @ref TF1_TM_QUEUE_CFG__PFC_COS "pfc_cos" | @ref bf_tm_q_pfc_cos_mapping_set() |  |

*/

/** @addtogroup TF1_TM_QUEUE_MAP

    @note @ref BFRT_TM_PORT_TO_QUEUE_REL_DIAG "Queue to Port mapping diagram."

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_QUEUE_MAP__INGRESS_QID_COUNT "ingress_qid_count" | @ref bf_tm_port_q_mapping_get() |  |
| @ref TF1_TM_QUEUE_MAP__INGRESS_QID_LIST "ingress_qid_list" | @ref bf_tm_port_q_mapping_get() |  |

*/

/** @addtogroup TF1_TM_QUEUE_BUFFER

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_QUEUE_BUFFER__GUARANTEED_CELLS "guaranteed_cells" | @ref bf_tm_q_guaranteed_min_limit_get(), bf_tm_q_guaranteed_min_limit_set() | Also known as the 'green' color limit. |
| @ref TF1_TM_QUEUE_BUFFER__HYSTERESIS_CELLS "hysteresis_cells" | @ref bf_tm_q_hysteresis_get(), bf_tm_q_hysteresis_set(), bf_tm_q_app_pool_usage_get(), bf_tm_q_app_pool_usage_set() | |
| @ref TF1_TM_QUEUE_BUFFER__TAIL_DROP_ENABLE "tail_drop_enable" | @ref bf_tm_q_tail_drop_get(), bf_tm_q_tail_drop_enable(), bf_tm_q_tail_drop_disable() | |
| @ref TF1_TM_QUEUE_BUFFER__BUFFER_ONLY "'buffer_only' action" | @ref bf_tm_q_app_pool_usage_disable(), bf_tm_q_app_pool_limit_get() | The queue will not use a shared pool, but only the guaranteed_cells buffer which is allocated to the queue. The action_id value after a BfRtTable::tableEntryGet() operation allows to determine the current buffering mode: a data object having ‘buffer_only’ action_id  will change it to 'shared_pool' to inform that this mode is currently active for the queue (see pool_max_cells data field).  Another BfRtTable::tableEntryGet() with this data object will fetch data for the current buffering mode if needed. |
| @ref TF1_TM_QUEUE_BUFFER__SHARED_POOL__POOL_ID "pool_id" | @ref bf_tm_q_app_pool_usage_get(), @ref bf_tm_q_app_pool_usage_set() | The queue is always assigned to some pool, but its actual usage depends on pool_max_cells non-zero value |
| @ref TF1_TM_QUEUE_BUFFER__SHARED_POOL__POOL_MAX_CELLS "pool_max_cells" |^| |
| @ref TF1_TM_QUEUE_BUFFER__SHARED_POOL__DYNAMIC_BAF "dynamic_baf" |^| |

*/

/** @addtogroup TF1_TM_QUEUE_COLOR

    ### See also ###

| Action / Data field | TM API | Other data fields |
| :------------------ | :----- | :---------------- |
| @ref TF1_TM_QUEUE_COLOR__DROP_ENABLE "drop_enable" | @ref bf_tm_q_color_drop_get()i, bf_tm_q_color_drop_enable(), bf_tm_q_color_drop_disable() |  |
| @ref TF1_TM_QUEUE_COLOR__DROP_LIMIT_YELLOW "drop_limit_yellow" | @ref bf_tm_q_color_limit_get(), bf_tm_q_color_limit_set() | Queue color drop limit in % of the 'green' color limit which is @ref TF1_TM_QUEUE_BUFFER__GUARANTEED_CELLS "tm.queue.buffer.guaranteed_cells" value |
| @ref TF1_TM_QUEUE_COLOR__DROP_LIMIT_RED "drop_limit_red" |^|^|
| @ref TF1_TM_QUEUE_COLOR__HYSTERESIS_YELLOW_CELLS "hysteresis_yellow_cells" | @ref bf_tm_q_color_hysteresis_get(), bf_tm_q_color_hysteresis_set() | |
| @ref TF1_TM_QUEUE_COLOR__HYSTERESIS_RED_CELLS "hysteresis_red_cells" |^| |

*/

/** @addtogroup TF1_TM_QUEUE_SCHED_CFG

    ### See also ###

    <table>
    <tr>
      <th>Action / Data field</th>
      <th>TM API</th>
      <th>Other data fields</th>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_CFG__SCHEDULING_ENABLE  "scheduling_enable"</td>
      <td> @ref bf_tm_sched_q_enable_get(), bf_tm_sched_q_enable(), bf_tm_sched_q_disable()</td>
      <td>This field will be last in the entry to be written into HW.</td>
    </tr>
    <tr>
      <td colspan=3><b>Guaranteed (minimum) bandwidth.</b></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_CFG__MIN_RATE_ENABLE  "min_rate_enable"</td>
      <td> @ref bf_tm_sched_q_guaranteed_enable_get(), bf_tm_sched_q_guaranteed_rate_enable(), bf_tm_sched_q_guaranteed_rate_disable()</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_CFG__MIN_PRIORITY  "min_priority"</td>
      <td> @ref bf_tm_sched_q_priority_get(), bf_tm_sched_q_priority_set()</td>
      <td></td>
    </tr>
    <tr>
      <td colspan=3><b>Shaping (maximum) bandwidth.</b></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_CFG__MAX_RATE_ENABLE  "max_rate_enable"</td>
      <td> @ref bf_tm_sched_q_shaping_rate_get(), bf_tm_sched_q_max_shaping_rate_enable(), bf_tm_sched_q_max_shaping_rate_disable()</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_CFG__MAX_PRIORITY  "max_priority"</td>
      <td> @ref bf_tm_sched_q_remaining_bw_priority_get(), bf_tm_sched_q_remaining_bw_priority_set()</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_CFG__DWRR_WEIGHT  "dwrr_weight"</td>
      <td> @ref bf_tm_sched_q_dwrr_weight_get(), bf_tm_sched_q_dwrr_weight_set()</td>
      <td>The weight is used when queues at same priority level are scheduled during excess bandwidth sharing.</td>
    </tr>
  </table>
*/

/** @addtogroup TF1_TM_QUEUE_SCHED_SHAPING

    ### See also ###

    <table>
    <tr>
      <th>Action / Data field</th>
      <th>TM API</th>
      <th>Other data fields</th>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_SHAPING__PROVISIONING  "provisioning"</td>
      <td rowspan=4> @ref bf_tm_sched_q_shaping_rate_set_provisioning(), bf_tm_sched_q_shaping_rate_set(), bf_tm_sched_q_shaping_rate_get_provisioning(), bf_tm_sched_q_shaping_rate_get()</td>
      <td>
        <ul>
        <li>Upper limit for the rate, Over-provisioning; </li>
        <li>Lower limit for the rate, Under-provisioning; </li>
        <li>Min Error between the Upper/Lower rate. </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_SHAPING__UNIT "unit"</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_SHAPING__MAX_RATE "max_rate"</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_SHAPING__MAX_BURST_SIZE "max_burst_size"</td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_SHAPING__MIN_RATE "min_rate"</td>
      <td rospan=2></td> @ref bf_tm_sched_q_guaranteed_rate_get(), bf_tm_sched_q_guaranteed_rate_set() </td>
      <td></td>
    </tr>
    <tr>
      <td> @ref TF1_TM_QUEUE_SCHED_SHAPING__MIN_BURST_SIZE "min_burst_size"</td>
      <td></td>
    </tr>
  </table>
*/

